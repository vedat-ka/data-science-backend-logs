# ML Log Analyzer

Ein Dockerâ€‘basiertes Projekt zum **Atomisieren**, **Analysieren** und **Trainieren** von Logâ€‘Daten mit ML.  
**Motivation:** Logs sind oft unstrukturiert und schwer auswertbar. Dieses Projekt macht sie automatisch MLâ€‘tauglich, erkennt Muster/FehlergrÃ¼nde und liefert verwertbare Reports fÃ¼r Betrieb und QualitÃ¤t.  
**Zusatznutzen:** Die Auswertung unterstÃ¼tzt auch bessere Softwareâ€‘EntwÃ¼rfe und Codeâ€‘QualitÃ¤t, z.â€¯B. durch das Erkennen von Hotspots, hÃ¤ufigen Fehlerrouten, wiederkehrenden Ursachen und instabilen Komponenten.

Frontend und Backend laufen getrennt in Containern.
---

## âœ¨ Features

- Logs aus `data/` analysieren (JSONL / JSON)
- Rawâ€‘Logs atomisieren (z.â€¯B. `.log`, `.txt`)
- Dateien splitten (max. 4â€¯MB)
- MLâ€‘Modelle trainieren und speichern
- Reports fÃ¼r Training und Analyse mit UIâ€‘Anzeige

---

## ğŸ“ Projektstruktur (relativ)

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ train.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ models/
â”œâ”€â”€ training/
â”œâ”€â”€ analysis/
â”œâ”€â”€ data/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ app.js
â”‚   â””â”€â”€ styles.css
â””â”€â”€ scripts/
```

---

## âœ… Voraussetzungen

- Docker + Docker Compose

---

## â–¶ï¸ Start (Docker)

```
docker compose up --build
```

**Frontend:** http://127.0.0.1:8090  
**Backend:** http://127.0.0.1:5050

---

## ğŸ“¦ Daten (relativ)

- Rawâ€‘Logs: `data/*.log` oder `data/*.txt`
- Atomisierte Logs: `data/*.jsonl`
- Analysen: `analysis/*.json`
- Trainingsâ€‘Reports: `training/*.json`
- Modelle: `models/*.joblib`

---

## ğŸ§­ Logâ€‘Quellen & Workflow

**Woher kommen die Logs?**

- Dateiâ€‘Logs aus deinem Backend/Service (z.â€¯B. Rotationsâ€‘Logs)
- Export aus einer Datenbank (z.â€¯B. mongoexport JSON / JSONL)
- Bereits atomisierte JSONLâ€‘Logs aus bestehenden Pipelines

**Workflow (kurz):**

1. Logs per UI hochladen (roh: `.log`/`.txt` oder atomisiert: `.json`/`.jsonl`).
2. Falls roh â†’ im UI **Atomisieren** starten (erzeugt `.jsonl` in `data/`).
3. Bei groÃŸen Dateien â†’ **Splitten** nutzen (â‰¤ 4â€¯MBâ€‘Chunks in `data/`).
4. **Analysieren** â†’ Report in `analysis/`, im UI unter **Analyseâ€‘Reports** Ã¶ffnen.
5. **Trainieren** â†’ Modelle in `models/`, Report in `training/`.

---

## ğŸ§ª Training

1. JSONLâ€‘Datei per UI hochladen (oder in `data/` ablegen)  
2. Im UI â†’ **Trainieren** starten  
3. Reports erscheinen unter **Trainingâ€‘Reports**

Beim Training werden drei Modelle erstellt (sofern Labels vorhanden sind):

- `models/model_priority.joblib` (PrioritÃ¤t)
- `models/model_category.joblib` (Kategorie)
- `models/model_reason.joblib` (Grund/Reason)

ZusÃ¤tzlich wird `models/meta.json` gespeichert. Dort stehen die
Trainingsâ€‘Metriken (Classification Report) je Modell sowie die verwendete
Trainingsdatei. Jeder Trainingslauf erzeugt auÃŸerdem einen Report in
`training/` (z.â€¯B. `training_20260201T114920Z.json`), der im UI unter
**Trainingâ€‘Reports** geÃ¶ffnet werden kann.

Hinweis: Neue TrainingslÃ¤ufe **Ã¼berschreiben** die Modellâ€‘Dateien in
`models/`, die Reports in `training/` bleiben jedoch erhalten.

---

## ğŸ” Analyse

1. JSONLâ€‘Datei per UI hochladen (oder in `data/` ablegen)  
2. Im UI â†’ **Analysieren** (der Ablauf wird vollstÃ¤ndig Ã¼ber die UI gesteuert)  
3. Ergebnisse werden in `analysis/` gespeichert  
4. **Analyseâ€‘Reports** im UI Ã¶ffnen

---

## ğŸ§© Atomisieren / Splitten

- **Rawâ€‘Logs atomisieren**: `.txt` / `.log` â†’ `.jsonl`
- **Splitten**: groÃŸe `.json`/`.jsonl` in â‰¤ 4â€¯MB StÃ¼cke

---

## âš™ï¸ Konfiguration (Environment)

| Variable | Standard |
|---------|----------|
| `ML_LOG_ANALYZER_PORT` | `5050` |
| `ML_LOG_ANALYZER_MODEL_DIR` | `models` |
| `ML_LOG_ANALYZER_DATA_DIR` | `data` |
| `ML_LOG_ANALYZER_TRAINING_DIR` | `training` |
| `ML_LOG_ANALYZER_ANALYSIS_DIR` | `analysis` |

---

## ğŸ“„ Lizenz 

MIT